---
layout: single
title:  "[PKOS STUDY #3] - 깃옵스 시스템 "
---

![](https://velog.velcdn.com/images/yuran3391/post/d270a1c9-a915-41fb-be50-2ee9f10fa38a/image.png)

> **이정훈님의 ‘24단계 실습으로 정복하는 쿠버네티스’ 기반으로 작성된 포스팅 입니다.**
도서 링크 : http://www.yes24.com/Product/Goods/115187666
![](https://velog.velcdn.com/images/yuran3391/post/429d18dd-2f0f-40c7-a1f8-789f8171ea5b/image.png)



## 목표 아키텍처

![](https://velog.velcdn.com/images/yuran3391/post/809e3ac8-10de-490c-af78-a278f6886877/image.png)

## 실습환경 배포
### kops 인스턴스 t3.small & 노드 c5a.2xlarge (AMD vCPU 8, Memory 16GiB) 배포 : 이번주 실습에서 성능을 요구하는 파드를 사용함
```
# YAML 파일 다운로드
curl -O https://s3.ap-northeast-2.amazonaws.com/cloudformation.cloudneta.net/K8S/kops-oneclick-f1.yaml

# CloudFormation 스택 배포 : 노드 인스턴스 타입 변경 - MasterNodeInstanceType=t3.medium WorkerNodeInstanceType=c5d.large
aws cloudformation deploy --template-file kops-oneclick-f1.yaml --stack-name mykops --parameter-overrides KeyName=xxx SgIngressSshCidr=$(curl -s ipinfo.io/ip)/32  MyIamUserAccessKeyID=AKIA5... MyIamUserSecretAccessKey='CVNa2...' ClusterBaseName='yuran.link' S3StateStore='yuran06141' MasterNodeInstanceType=c5a.2xlarge WorkerNodeInstanceType=c5a.2xlarge --region ap-northeast-2

# CloudFormation 스택 배포 완료 후 kOps EC2 IP 출력
aws cloudformation describe-stacks --stack-name mykops --query 'Stacks[*].Outputs[0].OutputValue' --output text

# 13분 후 작업 SSH 접속
ssh -i ~/.ssh/xxx.pem ec2-user@$(aws cloudformation describe-stacks --stack-name mykops --query 'Stacks[*].Outputs[0].OutputValue' --output text)

# EC2 instance profiles 에 IAM Policy 추가(attach) : 처음 입력 시 적용이 잘 안될 경우 다시 한번 더 입력 하자! - IAM Role에서 새로고침 먼저 확인!
aws iam attach-role-policy --policy-arn arn:aws:iam::$ACCOUNT_ID:policy/AWSLoadBalancerControllerIAMPolicy --role-name masters.$KOPS_CLUSTER_NAME
aws iam attach-role-policy --policy-arn arn:aws:iam::$ACCOUNT_ID:policy/AWSLoadBalancerControllerIAMPolicy --role-name nodes.$KOPS_CLUSTER_NAME

# 메트릭 서버 확인 : 메트릭은 15초 간격으로 cAdvisor를 통하여 가져옴
kubectl top node
```

### kops 인스턴스 t3.small : 도커 엔진 설치 확인
```
# default NS 진입
kubectl ns default


# 설치된 패키지 확인 : 도커 엔진 확인
yum list installed

# 도커 정보 확인 : client - server, Docker Root Dir, Registry
docker info

# bridge 통한 트래픽을 iptables로 통제 설정
echo "net.bridge.bridge-nf-call-iptables = 1" >> /etc/sysctl.conf
echo "net.bridge.bridge-nf-call-ip6tables = 1" >> /etc/sysctl.conf
sysctl -p
docker info

# 도커 정보 확인 : Docker Engine - Community
docker version

# 도커 서비스 상태 확인
systemctl status docker

# 모든 서비스의 상태 표시 - 링크
systemctl list-units --type=service

# 도커 루트 디렉터리 확인
tree -L 3 /var/lib/docker
```

## 하버(Harbor)를 이용하여 로컬 컨테이너 이미지 저장소 구축하기
- 헬름 차트로 하버 설치 

```
# 사용 리전의 인증서 ARN 확인
aws acm list-certificates --query 'CertificateSummaryList[].CertificateArn[]' --output text
CERT_ARN=`aws acm list-certificates --query 'CertificateSummaryList[].CertificateArn[]' --output text`
echo "alb.ingress.kubernetes.io/certificate-arn: $CERT_ARN"

# 하버 설치
helm repo add harbor https://helm.goharbor.io
helm fetch harbor/harbor --untar --version 1.11.0
vim ~/harbor/values.yaml
----------------------
expose.tls.certSource=none                        # 19줄
>> alb 인증서 쓸거니까 
expose.ingress.hosts.core=harbor.<각자자신의도메인>    # 36줄
expose.ingress.hosts.notary=notary.<각자자신의도메인>  # 37줄
expose.ingress.hosts.core=harbor.gasida.link
expose.ingress.hosts.notary=notary.gasida.link
expose.ingress.controller=alb                      # 44줄
expose.ingress.className=alb                       # 47줄~
expose.ingress.annotations=alb.ingress.kubernetes.io/scheme: internet-facing
expose.ingress.annotations=alb.ingress.kubernetes.io/target-type: ip
expose.ingress.annotations=alb.ingress.kubernetes.io/listen-ports: '[{"HTTPS":443}, {"HTTP":80}]'
expose.ingress.annotations=alb.ingress.kubernetes.io/certificate-arn: ${CERT_ARN}   # 각자 자신의 값으로 수정입력
alb.ingress.kubernetes.io/scheme: internet-facing
alb.ingress.kubernetes.io/target-type: ip
alb.ingress.kubernetes.io/listen-ports: '[{"HTTPS":443}, {"HTTP":80}]'
alb.ingress.kubernetes.io/certificate-arn: ${CERT_ARN}   # 각자 자신의 값으로 수정입력
externalURL=https://harbor.<각자자신의도메인>          # 131줄
externalURL=https://harbor.gasida.link             
----------------------

# 모니터링
kubectl create ns harbor
watch kubectl get pod,pvc,ingress -n harbor

# 설치
helm install harbor harbor/harbor -f ~/harbor/values.yaml --namespace harbor --version 1.11.0

# 확인
# registry : 컨테이너 이미지를 저장
# chartmuseum : 하버를 컨테이너 이미지뿐 아니라, 헬름 차트 리포지토리로도 사용
# notary : 서명이 완료된 컨테이너 이미지만 운영 환경에 사용하도록 설정. 서명이 완료된 이미지는 별도로 구분
# trivy : 컨테이너 이미지의 보안 취약점을 스캔, 스캔 기능은 별도 솔루션에서 제공하여 관리자는 보안 스캔용 도구를 선택 가능
helm list -n harbor
kubectl get-all -n harbor
kubectl get pod,pvc,ingress,deploy,sts -n harbor
kubectl get ingress -n harbor harbor-ingress -o json | jq
kubectl krew install df-pv && kubectl df-pv

# 웹 접속 주소 확인 및 접속
echo -e "harbor URL = https://harbor.$KOPS_CLUSTER_NAME"
echo -e "notary URL = https://notary.$KOPS_CLUSTER_NAME"
```

![](https://velog.velcdn.com/images/yuran3391/post/b11d1543-538a-414c-8baa-6c62111d1807/image.png)

```
(yuran:default) [root@kops-ec2 ~]# helm list -n harbor
NAME  	NAMESPACE	REVISION	UPDATED                                	STATUS  	CHART        	APP VERSION
harbor	harbor   	1       	2023-03-25 22:21:59.534027638 +0900 KST	deployed	harbor-1.11.0	2.7.0
(yuran:default) [root@kops-ec2 ~]# kubectl get pod,pvc,ingress,deploy,sts -n harbor
NAME                                        READY   STATUS    RESTARTS   AGE
pod/harbor-chartmuseum-746ff5db5-9bpr5      1/1     Running   0          3m20s
pod/harbor-core-7c999cd649-vvk2r            1/1     Running   0          3m21s
pod/harbor-database-0                       1/1     Running   0          3m20s
pod/harbor-jobservice-bf8658c45-zpvqk       1/1     Running   0          3m21s
pod/harbor-notary-server-5665c4cd-w9cgf     1/1     Running   0          3m21s
pod/harbor-notary-signer-779857df4b-gr62v   1/1     Running   0          3m21s
pod/harbor-portal-d74b69db4-8jrrs           1/1     Running   0          3m21s
pod/harbor-redis-0                          1/1     Running   0          3m20s
pod/harbor-registry-5574f94875-fb2g2        2/2     Running   0          3m20s
pod/harbor-trivy-0                          1/1     Running   0          3m20s

NAME                                                    STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS    AGE
persistentvolumeclaim/data-harbor-redis-0               Bound    pvc-3fc07a8b-da12-4157-8926-cf2af05d58c9   1Gi        RWO            kops-csi-1-21   3m20s
persistentvolumeclaim/data-harbor-trivy-0               Bound    pvc-2676e4b1-9904-42c5-8c73-ce5d139d0f46   5Gi        RWO            kops-csi-1-21   3m20s
persistentvolumeclaim/database-data-harbor-database-0   Bound    pvc-4a0ff7c5-2d72-49b7-b071-442673ad9807   1Gi        RWO            kops-csi-1-21   3m20s
persistentvolumeclaim/harbor-chartmuseum                Bound    pvc-f343e239-498d-4952-a6fd-54a9ae24dbd1   5Gi        RWO            kops-csi-1-21   3m21s
persistentvolumeclaim/harbor-jobservice                 Bound    pvc-3c980122-082f-4ab8-84c9-5b6ba3324366   1Gi        RWO            kops-csi-1-21   3m21s
persistentvolumeclaim/harbor-jobservice-scandata        Bound    pvc-27eca19e-c1c8-42c7-8a77-3a54ad802655   1Gi        RWO            kops-csi-1-21   3m21s
persistentvolumeclaim/harbor-registry                   Bound    pvc-d57254a5-78ba-408d-b3a6-f7db81379930   5Gi        RWO            kops-csi-1-21   3m21s

NAME                                              CLASS   HOSTS               ADDRESS   PORTS     AGE
ingress.networking.k8s.io/harbor-ingress          alb     core.yuran.link               80, 443   3m21s
ingress.networking.k8s.io/harbor-ingress-notary   alb     notary.yuran.link             80, 443   3m21s

NAME                                   READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/harbor-chartmuseum     1/1     1            1           3m21s
deployment.apps/harbor-core            1/1     1            1           3m21s
deployment.apps/harbor-jobservice      1/1     1            1           3m21s
deployment.apps/harbor-notary-server   1/1     1            1           3m21s
deployment.apps/harbor-notary-signer   1/1     1            1           3m21s
deployment.apps/harbor-portal          1/1     1            1           3m21s
deployment.apps/harbor-registry        1/1     1            1           3m21s

NAME                               READY   AGE
statefulset.apps/harbor-database   1/1     3m21s
statefulset.apps/harbor-redis      1/1     3m21s
statefulset.apps/harbor-trivy      1/1     3m21s
```


### 하버 웹 접속 및 로컬 이미지 업로드:
```
(yuran:default) [root@kops-ec2 ~]# echo -e "harbor URL = https://harbor.$KOPS_CLUSTER_NAME"
harbor URL = https://harbor.yuran.link
```
#### 하버 웹 접속 및 로컬 이미지 업로드:  `https://harbor.<각자 자신의 도메인>`
    - 로그인 : admin/Harbor12345
    - NEW PROJECT → Name(**pkos**), Access Level(Public Check) ⇒ OK 클릭
        - 신규 프로젝트 생성 : 프로젝트 단위로 컨테이너 이미지 저장소를 관리, 프로젝트 별로 사용자 권한(RBAC) 보안 설정이 가능
    - kops-ec2 에서 로컬 이미지를 원격 하버 이미지 저장소로 업로드

```
# 컨테이너 이미지 가져오기
docker pull nginx && docker pull busybox && docker images

# 태그 설정
docker tag busybox harbor.$KOPS_CLUSTER_NAME/pkos/busybox:0.1
docker image ls

# 로그인 - 방안2
echo 'Harbor12345' > harborpw.txt
cat harborpw.txt | docker login harbor.$KOPS_CLUSTER_NAME -u admin --password-stdin
cat /root/.docker/config.json | jq

# 이미지 업로드
docker push harbor.$KOPS_CLUSTER_NAME/pkos/busybox:0.1```
```
###  깃랩(GitLab)를 이용하여 로컬 깃(Git) 소스 저장소 구축

`목표` : 자신만의 텍스트 파일을 kops-ec2 로컬에서 **Gitlab** Repo에 올려보고, 다운로드 받아보세요

`소개` : 무료 오픈소스로 사용 가능한 소스 코드 원격 저장소, 최소 Spec(4CPU, 4Mem, Disk 40GB) - [Requirements](https://docs.gitlab.com/ee/install/requirements.html) [Pricing](https://about.gitlab.com/pricing/) [GetStarted](https://about.gitlab.com/get-started/)

- 헬름 차트로 깃랩 설치 후 웹 로그인 - [HelmChart](https://artifacthub.io/packages/helm/gitlab/gitlab) [Docs](https://docs.gitlab.com/charts/)

```
# 모니터링
kubectl create ns gitlab
watch kubectl get pod,pvc,ingress -n gitlab

# 설치
echo $CERT_ARN
helm repo add gitlab https://charts.gitlab.io/
helm repo update
helm fetch gitlab/gitlab --untar --version 6.8.1
vim ~/gitlab/values.yaml
----------------------
global:
  hosts:
    domain: <각자자신의도메인>             # 52줄
    https: true

  ingress:                             # 66줄~
    configureCertmanager: false
    provider: aws
    class: alb
    annotations:
      alb.ingress.kubernetes.io/scheme: internet-facing
      alb.ingress.kubernetes.io/target-type: ip
      alb.ingress.kubernetes.io/listen-ports: '[{"HTTPS":443}, {"HTTP":80}]'
      alb.ingress.kubernetes.io/certificate-arn: ${CERT_ARN}   # 각자 자신의 값으로 수정입력
      alb.ingress.kubernetes.io/success-codes: 200-399
      alb.ingress.kubernetes.io/group.name: "gitlab"
    tls:                               # 79줄
      enabled: false
----------------------
helm install gitlab gitlab/gitlab -f ~/gitlab/values.yaml --set certmanager.install=false --set nginx-ingress.enabled=false --set prometheus.install=false --set gitlab-runner.install=false --namespace gitlab --version 6.8.4

# 확인 - SubCharts
# gitlab-gitaly : 웹서비스 혹은 ssh 방식으로 진행되는 깃 제목, 브랜치, 태그 등의 깃 요청 등에 대한 작업을 담당
# gitlab-gitlab-shell : https 가 아닌 ssh 방식으로 깃 명령어 실행 시 해당 요청을 처리
# gitlab-kas : gitlab agent server
# gitlab-postgresql : 유저, 권한, 이슈 등 깃랩의 메타 데이터 정보가 저장
# gitlab-redis-master : 깃랩 작업 정보는 레디스 캐시 서버를 이용하여 처리
# gitlab-sidekiq-all-in-1-v2 : 레디스와 연동하여 작업 큐 처리 용도로 사용
# gitlab-webservice-default : 깃랩 웹 서비스를 처리
helm list -n gitlab
kubectl get pod,pvc,ingress,deploy,sts -n gitlab
kubectl df-pv -n gitlab
kubectl get-all -n gitlab

@@ 4개의 Ingress 가 1개의 ALB를 공유해서 사용 : ALB의 Rule 확인해볼것!
# alb.ingress.kubernetes.io/group.name: "gitlab"
(yuran:default) [root@kops-ec2 ~]# kubectl get ingress -n gitlab
NAME                        CLASS   HOSTS                 ADDRESS                                                             PORTS   AGE
gitlab-kas                  alb     kas.yuran.link        k8s-gitlab-1430a128c6-1455294576.ap-northeast-2.elb.amazonaws.com   80      94s
gitlab-minio                alb     minio.yuran.link      k8s-gitlab-1430a128c6-1455294576.ap-northeast-2.elb.amazonaws.com   80      94s
gitlab-registry             alb     registry.yuran.link   k8s-gitlab-1430a128c6-1455294576.ap-northeast-2.elb.amazonaws.com   80      94s
gitlab-webservice-default   alb     gitlab.yuran.link     k8s-gitlab-1430a128c6-1455294576.ap-northeast-2.elb.amazonaws.com   80      94s

# 웹 root 계정 암호 확인
kubectl get secrets -n gitlab gitlab-gitlab-initial-root-password --template={{.data.password}} | base64 -d ;echo
hhBvAjXoANx8kVIVpcwdgvc6A0kFDIIQFxikRDJfwVPBXn0dxmNBgc7zssSBskTj

# 웹 접속 주소 확인 및 접속
echo -e "gitlab URL = https://gitlab.$KOPS_CLUSTER_NAME"

# 웹 접속 https://gitlab.<각자 자신의 도메인> (root / 웹 root 계정 암호)
```

![](https://velog.velcdn.com/images/yuran3391/post/2265096d-caa3-4837-8812-11f2161adfa9/image.png)
![](https://velog.velcdn.com/images/yuran3391/post/5b18d5bb-9a64-4818-bf7a-0f85eb582b1c/image.png)


**4개의 Ingress 가 1개의 ALB를 공유해서 사용 : ALB의 Rule 확인**

>and 조건으로 rule match를 하기때문에

#### **접속 후 별도의 사용자 생성** : Admins → Users : 각자 자신만의 편한 계정 (gasida , gasida@cloudneta.net, Administrator 권한 부여) ⇒ 해당 계정으로 git 명령어 실행
    - Impersonation Tokens : Name(test), Scopes(모두 Check) → Create impersonation token 클릭 ⇒ 토큰 값 확인  `glpat-cGRP-NvXCHbjJUfRnZit`
- **Users** : 유저 선택 후 암호 입력(**Test1234**), admin 권한 체크 ⇒ root 계정 **로그아웃** ⇒ gasida 계정 **로그인** ⇒ 암호 변경(**P@ssw0rd**)
![](https://velog.velcdn.com/images/yuran3391/post/d66fb9d2-144d-4b22-aed5-4a12012d6cda/image.png)

깃랩 신규 프로젝트 작성 : Project name (test-stg) , Project URL(<각자계정>, /test-stg) , Visibility Level (Intenal) , Initialize repository with a README (체크)
![](https://velog.velcdn.com/images/yuran3391/post/b9a23806-972e-44f8-8afb-7d69a300007f/image.png)

생성한 깃랩 프로젝트에 쿠버네티스에서 사용하는 YAML 파일을 업로드 ⇒ 토큰 값 확인  
```
#
mkdir ~/gitlab-test && cd ~/gitlab-test

# git 계정 초기화 : 토큰 및 로그인 실패 시 매번 실행해주자
git config --system --unset credential.helper

# git 계정 정보 확인 및 global 계정 정보 입력
git config --list
git config --global user.name 

git config --global user.name "yuran3391"
git config --global user.email "yuran3391@gmail.com"

# git clone
git clone https://gitlab.$KOPS_CLUSTER_NAME/<각자 자신의 Gitlab 계정>/test-stg.git

git clone https://gitlab.$KOPS_CLUSTER_NAME/yuran3391/test-stg.git

Cloning into 'test-stg'...
Username for 'https://gitlab.gasida.link': gasida
Password for 'https://gasida@gitlab.gasida.link': <토큰 입력>

# 이동
ls -al test-stg && cd test-stg && pwd

# 파일 생성 및 깃 업로드(push) : 웹에서 확인
echo "gitlab test memo" >> test.txt
git add . && git commit -m "initial commit - add test.txt"
git push
Username for 'https://gitlab.gasida.link': gasida
Password for 'https://gasida@gitlab.gasida.link': <토큰 입력>

# 이동
ls -al test-stg && cd test-stg && pwd

# 파일 생성 및 깃 업로드(push) : 웹에서 확인
echo "gitlab test memo" >> test.txt
git add . && git commit -m "initial commit - add test.txt"
git push
Username for 'https://gitlab.yuran.link': gasida
Password for 'https://gasida@gitlab.yuran.link': <토큰 입력>
```
#### 아르고시디(ArgoCD)를 활용한 깃옵스(GitOps) 시스템 구축
Argo **CD** is a declarative, **GitOps** continuous delivery tool for **Kubernetes**.

- **지속적인 배포란**(Continuous Delivery, **CD**) 개발자가 소스코드를 변경해서 깃 저장소에 푸시하면 해당 변경 사항이 고객이 사용하는 실제 운영환경의 시스템까지 자동으로 반영함
    - 개발자의 코드가 원격 저장소에 업로드됐을 때 **아르고시디**가 자동으로 해당 코드를 클러스터 운영환경에 **배포**합니다.
    - **아르고시티**로 배포한 헬름 애플리케이션의 리소스 목록, 각 리소스 간 관계 및 에러 유무를 **UI**로 보여줍니다.
- **단일 진실 원천**(**SSOT**, Single Source Of Truth)이란 어떠한 진실(결과)의 원인이 하나의 이유(원천)에서 비롯되는 것을 의미합니다.
    - 쿠버네티스 환경에서 깃옵스의 의미는 실제 운영 중인 클러스터의 상태를 개발자의 로컬 PC혹은 아무런 기록을 남기지 않고 클러스터에서 임의로 수정하게 하지 않고 공용으로 관리하는 깃 저장소에서만 유일하게 변경을 허용함으로써 단일 진실 원천(SSOT)를 구현합니다.
    - **아르고시디**를 사용하면 쿠버네티스 매니페스트 **소스** 파일을 여러 개발자의 개인 PC에 보관하지 않고 중앙의 통합된 **깃 저장소**에 반드시 업로드하고 동기화하도록 정책 관리 가능함
    
```
# 모니터링
kubectl create ns argocd
watch kubectl get pod,pvc,svc -n argocd

# 설치
cd
helm repo add argo https://argoproj.github.io/argo-helm
helm repo update
helm install argocd argo/argo-cd --set server.service.type=LoadBalancer --namespace argocd --version 5.19.14

# 확인
# argocd-application-controller : 실행 중인 k8s 애플리케이션의 설정과 깃 저장소의 소스 파일에 선언된 상태를 서로 비교하는 컨트롤러. 상태와 다르면 ‘OutOfSync’ 에러를 출력.
# argocd-dex-server : 외부 사용자의 LDAP 인증에 Dex 서버를 사용할 수 있음
# argocd-repo-server : 원격 깃 저장소의 소스 코드를 아르고시디 내부 캐시 서버에 저장합니다. 디렉토리 경로, 소스, 헬름 차트 등이 저장.
helm list -n argocd
kubectl get pod,pvc,svc,deploy,sts -n argocd
kubectl get-all -n argocd

(yuran:default) [root@kops-ec2 ~]# kubectl get crd | grep argoproj
applications.argoproj.io              2023-03-25T15:24:05Z
applicationsets.argoproj.io           2023-03-25T15:24:05Z
appprojects.argoproj.io               2023-03-25T15:24:05Z

# CLB에 ExternanDNS 로 도메인 연결
(yuran:default) [root@kops-ec2 ~]# kubectl annotate service -n argocd argocd-server "external-dns.alpha.kubernetes.io/hostname=argocd.$KOPS_CLUSTER_NAME"
service/argocd-server annotated

# admin 계정의 암호 확인
(yuran:default) [root@kops-ec2 ~]# ARGOPW=$(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d)
(yuran:default) [root@kops-ec2 ~]# echo $ARGOPW
wV6acDlH4973UOEQ

# 웹 접속 로그인 (admin) CLB의 DNS 주소로 접속
echo -e "Argocd Web URL = https://argocd.$KOPS_CLUSTER_NAME"
```
